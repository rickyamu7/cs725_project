{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "GdUxdS1D_AaF",
        "epCb4Fpj_DDP",
        "zWoEFWGW7OzJ",
        "lhZKpB3q_nZ7",
        "Sf-avUlvByS_",
        "FBdyDX7Pv16i",
        "Q8di0xmxNjL0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Downloads"
      ],
      "metadata": {
        "id": "GdUxdS1D_AaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPJDdGSzTNPM",
        "outputId": "921cd803-3941-4ff0-9d7d-e413b1de42f0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.10)\n",
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 7.43 s (started: 2023-11-28 11:06:31 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install polars icecream scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIoG6FXk3o3U",
        "outputId": "fa3447e3-bd4b-4113-8493-41bd17dac27e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (0.17.3)\n",
            "Requirement already satisfied: icecream in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.3)\n",
            "Requirement already satisfied: typing_extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from polars) (4.5.0)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from icecream) (0.4.6)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.16.1)\n",
            "Requirement already satisfied: executing>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.0.1)\n",
            "Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.4.1)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.0.1->icecream) (1.16.0)\n",
            "time: 5.03 s (started: 2023-11-28 11:06:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "epCb4Fpj_DDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset\n",
        "# import gdown\n",
        "import gzip\n",
        "%load_ext autotime\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import torch.multiprocessing as mp\n",
        "from torchsummary import summary\n",
        "import polars as pl\n",
        "import math as m\n",
        "import numpy as np\n",
        "from icecream import ic\n",
        "from scipy.spatial.distance import pdist\n",
        "from scipy.spatial.distance import squareform\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvLu0g_hh91T",
        "outputId": "2d8978b8-bfa7-4f4d-d1c4-beb91cf81eae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 5.6 ms (started: 2023-11-28 11:06:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4DY6rEmmjsR",
        "outputId": "05b95739-a54c-4862-d5cc-60fd42c6bf24"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.4 ms (started: 2023-11-28 11:06:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YHih_Anl4B-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cda6ac8-13bf-4b54-d6b3-ff1607ad8fc4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "time: 4.08 s (started: 2023-11-28 11:06:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pickle  function"
      ],
      "metadata": {
        "id": "zWoEFWGW7OzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = r\"/content/drive/MyDrive/Colab Notebooks/FML_Project/\"\n",
        "def pickleThis(file,pklname):\n",
        "    with open(path+pklname+\".pkl\", 'wb') as f:\n",
        "        pickle.dump(file, f)\n",
        "\n",
        "def loadPickle(filename):\n",
        "    with open(path+filename, 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "metadata": {
        "id": "xCxOmp9F7TUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394411a2-72f0-4484-902b-aa8b9510639f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 794 Âµs (started: 2023-11-28 11:06:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the data\n",
        "\n",
        "- Creating pairs\n",
        "- Dataloader"
      ],
      "metadata": {
        "id": "lhZKpB3q_nZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = loadPickle(\"x_train.pkl\")\n",
        "x_val = loadPickle(\"x_val.pkl\")\n",
        "\n",
        "y_train = loadPickle(\"y_train.pkl\")\n",
        "y_val = loadPickle(\"y_val.pkl\")"
      ],
      "metadata": {
        "id": "1NyXg8AZ7dLy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "532083d3-4cd7-489b-83f5-a0e36a338fbb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 20.4 s (started: 2023-11-28 11:06:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "num_train_elements = len(x_train)\n",
        "num_val_elements = len(x_val)\n",
        "\n",
        "#random index orders for both train and val\n",
        "train_index_order = random.sample(range(num_train_elements), num_train_elements)\n",
        "val_index_order = random.sample(range(num_val_elements), num_val_elements)\n",
        "\n",
        "#shuffle data and labels for both train and val based on the random index orders\n",
        "x_train = np.array([x_train[i] for i in train_index_order])\n",
        "y_train = np.array([y_train[i] for i in train_index_order])\n",
        "\n",
        "x_val = np.array([x_val[i] for i in val_index_order])\n",
        "y_val = np.array([y_val[i] for i in val_index_order])"
      ],
      "metadata": {
        "id": "1qEY-iGts6wy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193bc3e5-1622-41cd-d501-c048109125ec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.85 s (started: 2023-11-28 11:07:37 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create pairs"
      ],
      "metadata": {
        "id": "Lvv_IntkFrhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pairs(FFT_inputs, labels):\n",
        "  InputPairs = []\n",
        "  labelPairs = []\n",
        "\n",
        "\n",
        "  fault_classes = 3\n",
        "  #Getting the indices of each class\n",
        "  indices = [np.where(labels ==i)[0] for i in range(fault_classes)]\n",
        "\n",
        "  for index in range(len(FFT_inputs)):\n",
        "    #Getting current input with index\n",
        "    Xi = FFT_inputs[index]\n",
        "    #getting the label of xi.\n",
        "    label = labels[index]\n",
        "\n",
        "    #Randomly choosing another labels from the same class\n",
        "    indB = np.random.choice(indices[label])\n",
        "    #corresponding Xj for this randomly selected label\n",
        "    Xj = FFT_inputs[indB]\n",
        "\n",
        "    InputPairs.append([Xi, Xj])\n",
        "    labelPairs.append([1])\n",
        "\n",
        "    #Getting a label where label is different than the current xi\n",
        "    diss_index = np.where(labels != label)[0]\n",
        "\n",
        "    #finding an image for this label\n",
        "    diss_Xj = FFT_inputs[np.random.choice(diss_index)]\n",
        "    InputPairs.append([Xi, diss_Xj])\n",
        "    labelPairs.append([0])\n",
        "\n",
        "  return (np.array(InputPairs), np.array(labelPairs))"
      ],
      "metadata": {
        "id": "HzahJh2AGLWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942b066c-87dd-47d5-ab13-5a19ec084cb2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 671 Âµs (started: 2023-11-28 11:07:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_trainpair, y_trainpair) = create_pairs(x_train, y_train)\n",
        "(x_valpair, y_valpair) = create_pairs(x_val, y_val)"
      ],
      "metadata": {
        "id": "yuoxfkr4GWBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd026e6c-4247-4740-a57d-64542e03b690"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 887 ms (started: 2023-11-28 11:07:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_trainpair.shape,x_valpair.shape)"
      ],
      "metadata": {
        "id": "AFCXJcaJOsak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9d2194-f9b8-4a12-c221-9f897d1d360a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9420, 2, 1, 10451) (4060, 2, 1, 10451)\n",
            "time: 2.39 ms (started: 2023-11-28 11:07:45 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convert to tensors and data-loader"
      ],
      "metadata": {
        "id": "1R09grWVHZRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1028\n",
        "class TransformDataset(Dataset):\n",
        "    def __init__(self, pairs, labels):\n",
        "        self.pairs = pairs\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        pair = self.pairs[index]\n",
        "        label = self.labels[index]\n",
        "        return torch.tensor(pair[0], dtype=torch.float32), torch.tensor(pair[1], dtype=torch.float32), label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "def create_dataloader(pairs, labels, batch_size):\n",
        "    dataset = TransformDataset(pairs, labels)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    return dataloader\n",
        "\n",
        "train_dataloader = create_dataloader(x_trainpair, y_trainpair, batch_size)\n",
        "val_dataloader = create_dataloader(x_valpair, y_valpair, batch_size)"
      ],
      "metadata": {
        "id": "_l2pDCZAd_3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59fcc6c-0fc8-42cc-a4b9-149eb35c4f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.6 ms (started: 2023-11-28 06:45:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_batch = next(iter(TransformDataset(x_trainpair, y_trainpair)))\n",
        "print(\"Sample Batch from Siamese Dataset:\")\n",
        "for i, data in enumerate(sample_batch):\n",
        "    print(f\"Data {i} shape: {data.shape}\")\n",
        "\n",
        "\n",
        "dataiter = iter(train_dataloader)\n",
        "input1, input2, label = next(dataiter)\n",
        "\n",
        "print(\"\\nBatch from Siamese Data Loader:\")\n",
        "print(\"Input 1:\")\n",
        "print(f\"Input 1 shape: {input1.shape}\")\n",
        "print(\"\\nInput 2:\")\n",
        "print(f\"Input 2 shape: {input2.shape}\")\n",
        "\n",
        "print(\"\\nLabels:\")\n",
        "print(f\"Labels shape: {label.shape}\")"
      ],
      "metadata": {
        "id": "-ABwSdWPeBv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3841c0-c9a3-4403-f711-8d95c01b9e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Batch from Siamese Dataset:\n",
            "Data 0 shape: torch.Size([1, 10451])\n",
            "Data 1 shape: torch.Size([1, 10451])\n",
            "Data 2 shape: (1,)\n",
            "\n",
            "Batch from Siamese Data Loader:\n",
            "Input 1:\n",
            "Input 1 shape: torch.Size([1028, 1, 10451])\n",
            "\n",
            "Input 2:\n",
            "Input 2 shape: torch.Size([1028, 1, 10451])\n",
            "\n",
            "Labels:\n",
            "Labels shape: torch.Size([1028, 1])\n",
            "time: 132 ms (started: 2023-11-28 06:45:29 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SNN architecture"
      ],
      "metadata": {
        "id": "Sf-avUlvByS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Sequential(\n",
        "\n",
        "\n",
        "            nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=\"same\"),\n",
        "            nn.BatchNorm1d(8),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool1d(2),\n",
        "\n",
        "\n",
        "            nn.Conv1d(in_channels=8, out_channels=12, kernel_size=3, stride=1, padding=\"same\"),\n",
        "            nn.BatchNorm1d(12),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool1d(2),\n",
        "        )\n",
        "\n",
        "        #the fully connected layers\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(2612 * 12, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(1024, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(128,2),\n",
        "            )\n",
        "\n",
        "\n",
        "    def forward_once(self, x):\n",
        "\n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # forward pass of input 1\n",
        "        output1 = self.forward_once(input1)\n",
        "        # forward pass of input 2\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2"
      ],
      "metadata": {
        "id": "b_3HIpgv7hF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0643bff2-18ff-4858-afbf-e8a8b4210b1f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 912 Âµs (started: 2023-11-28 11:04:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model\n",
        "model = SNN()\n",
        "model = model.to(device)\n",
        "input1 = input1.to(device)\n",
        "input2 = input2.to(device)\n",
        "summary(model, [(1, 10451), (1, 10451)])"
      ],
      "metadata": {
        "id": "MEP_2FlRB2af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "187923c0-3dea-4d15-e2b6-65922abbcf04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv1d-1             [-1, 8, 10451]              32\n",
            "       BatchNorm1d-2             [-1, 8, 10451]              16\n",
            "              ReLU-3             [-1, 8, 10451]               0\n",
            "         AvgPool1d-4              [-1, 8, 5225]               0\n",
            "            Conv1d-5             [-1, 12, 5225]             300\n",
            "       BatchNorm1d-6             [-1, 12, 5225]              24\n",
            "              ReLU-7             [-1, 12, 5225]               0\n",
            "         AvgPool1d-8             [-1, 12, 2612]               0\n",
            "            Linear-9                 [-1, 1024]      32,097,280\n",
            "             ReLU-10                 [-1, 1024]               0\n",
            "           Linear-11                  [-1, 128]         131,200\n",
            "             ReLU-12                  [-1, 128]               0\n",
            "           Linear-13                    [-1, 2]             258\n",
            "           Conv1d-14             [-1, 8, 10451]              32\n",
            "      BatchNorm1d-15             [-1, 8, 10451]              16\n",
            "             ReLU-16             [-1, 8, 10451]               0\n",
            "        AvgPool1d-17              [-1, 8, 5225]               0\n",
            "           Conv1d-18             [-1, 12, 5225]             300\n",
            "      BatchNorm1d-19             [-1, 12, 5225]              24\n",
            "             ReLU-20             [-1, 12, 5225]               0\n",
            "        AvgPool1d-21             [-1, 12, 2612]               0\n",
            "           Linear-22                 [-1, 1024]      32,097,280\n",
            "             ReLU-23                 [-1, 1024]               0\n",
            "           Linear-24                  [-1, 128]         131,200\n",
            "             ReLU-25                  [-1, 128]               0\n",
            "           Linear-26                    [-1, 2]             258\n",
            "================================================================\n",
            "Total params: 64,458,220\n",
            "Trainable params: 64,458,220\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 416.65\n",
            "Forward/backward pass size (MB): 7.85\n",
            "Params size (MB): 245.89\n",
            "Estimated Total Size (MB): 670.39\n",
            "----------------------------------------------------------------\n",
            "time: 7.86 s (started: 2023-11-28 06:45:34 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Contrastive loss"
      ],
      "metadata": {
        "id": "3fKChXO_RyVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "    \"Contrastive loss function\"\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        loss_contrastive = torch.mean(\n",
        "            (1-label) * torch.pow(euclidean_distance, 2)+ (label)* torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "        return loss_contrastive"
      ],
      "metadata": {
        "id": "J7q6-anjHJBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ddcb59-6b0d-422a-e6a2-a00658c1c49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 663 Âµs (started: 2023-11-28 06:45:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = ContrastiveLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.0004)"
      ],
      "metadata": {
        "id": "UEhJhptWeYqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f29f39b-3b23-4261-c059-250c0f5ca0e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1 ms (started: 2023-11-28 06:45:50 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "iooVfO_DR11J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader):\n",
        "    loss = []\n",
        "    counter = []\n",
        "\n",
        "    with tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch} - Training\", unit=\"batch\") as pbar:\n",
        "        for i, data in enumerate(train_dataloader, 0):\n",
        "            x1, x2, label = data\n",
        "            x1, x2, label = x1.cuda(), x2.cuda(), label.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            output1, output2 = model(x1, x2)\n",
        "            loss_contrastive = criterion(output1, output2, label)\n",
        "            loss_contrastive.backward()\n",
        "            optimizer.step()\n",
        "            loss.append(loss_contrastive.item())\n",
        "\n",
        "            # Update the progress bar\n",
        "            pbar.update(1)\n",
        "    loss = np.array(loss)\n",
        "    return loss.mean() / len(train_dataloader)\n",
        "\n",
        "def eval(eval_dataloader):\n",
        "    loss = []\n",
        "\n",
        "    with tqdm(total=len(eval_dataloader)) as pbar:\n",
        "        for i, data in enumerate(eval_dataloader, 0):\n",
        "            x1, x2, label = data\n",
        "            x1, x2, label = x1.cuda(), x2.cuda(), label.cuda()\n",
        "            output1, output2 = model(x1, x2)\n",
        "\n",
        "            loss_contrastive = criterion(output1, output2, label)\n",
        "            loss.append(loss_contrastive.item())\n",
        "            pbar.update(1)\n",
        "\n",
        "    loss = np.array(loss)\n",
        "    return loss.mean() / len(eval_dataloader)"
      ],
      "metadata": {
        "id": "DGGe-yWJRlOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c260dca4-7b44-408b-af17-1cd2024a9707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.2 ms (started: 2023-11-28 06:48:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "wv7cn8TF6ETD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 10):\n",
        "    train_loss = train(train_dataloader)\n",
        "    eval_loss = eval(val_dataloader)\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Training loss: {train_loss}\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"\\nEval loss: {eval_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HufW5rdm9rfG",
        "outputId": "3d98deb1-b804-42eb-9853-12ea861cbd79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - Training: 100%|ââââââââââ| 10/10 [00:05<00:00,  1.96batch/s]\n",
            "100%|ââââââââââ| 4/4 [00:00<00:00,  4.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Training loss: 0.03859498649835587\n",
            "--------------------------------------------------\n",
            "Eval loss: 0.07650486752390862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - Training: 100%|ââââââââââ| 10/10 [00:04<00:00,  2.27batch/s]\n",
            "100%|ââââââââââ| 4/4 [00:00<00:00,  4.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Training loss: 0.029792310893535612\n",
            "--------------------------------------------------\n",
            "Eval loss: 0.07551160268485546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - Training: 100%|ââââââââââ| 10/10 [00:04<00:00,  2.26batch/s]\n",
            "100%|ââââââââââ| 4/4 [00:01<00:00,  3.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Training loss: 0.02940966159105301\n",
            "--------------------------------------------------\n",
            "Eval loss: 0.07521212100982666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - Training: 100%|ââââââââââ| 10/10 [00:04<00:00,  2.32batch/s]\n",
            "100%|ââââââââââ| 4/4 [00:00<00:00,  4.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Training loss: 0.02926946610212326\n",
            "--------------------------------------------------\n",
            "Eval loss: 0.07519312389194965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - Training: 100%|ââââââââââ| 10/10 [00:04<00:00,  2.27batch/s]\n",
            "100%|ââââââââââ| 4/4 [00:00<00:00,  4.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Training loss: 0.029071554839611054\n",
            "--------------------------------------------------\n",
            "Eval loss: 0.07528024539351463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 - Training: 100%|ââââââââââ| 10/10 [00:04<00:00,  2.19batch/s]\n",
            "100%|ââââââââââ| 4/4 [00:01<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Training loss: 0.029014154970645904\n",
            "--------------------------------------------------\n",
            "Eval loss: 0.07530809007585049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 - Training: 100%|ââââââââââ| 10/10 [00:04<00:00,  2.24batch/s]\n",
            "100%|ââââââââââ| 4/4 [00:00<00:00,  4.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Training loss: 0.028881066739559175\n",
            "--------------------------------------------------\n",
            "Eval loss: 0.07539464719593525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 - Training: 100%|ââââââââââ| 10/10 [00:04<00:00,  2.27batch/s]\n",
            "100%|ââââââââââ| 4/4 [00:00<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Training loss: 0.028919283151626583\n",
            "--------------------------------------------------\n",
            "Eval loss: 0.07562603428959846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 - Training: 100%|ââââââââââ| 10/10 [00:04<00:00,  2.16batch/s]\n",
            "100%|ââââââââââ| 4/4 [00:01<00:00,  3.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Training loss: 0.02895043581724167\n",
            "--------------------------------------------------\n",
            "Eval loss: 0.07527168281376362\n",
            "time: 49.6 s (started: 2023-11-28 06:48:54 +00:00)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Export and load model"
      ],
      "metadata": {
        "id": "FBdyDX7Pv16i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export\n",
        "torch.save(model, path+\"/model.pth\")"
      ],
      "metadata": {
        "id": "wmzwvX3sO_MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Demo"
      ],
      "metadata": {
        "id": "Q8di0xmxNjL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the data\n",
        "# df = pl.read_ipc(data_path)[1:]\n",
        "# train, val = create_train_test_split(df)\n",
        "# _, _, x_val, y_val  = create_dataset(df, train,val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVWYKdmcnBom",
        "outputId": "0bbd170c-9dfd-4e04-ca54-0c8090b5673d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 375 Âµs (started: 2023-11-28 11:05:55 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To load the model for inference\n",
        "loaded_model = torch.load(path+\"/model.pth\")\n",
        "loaded_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGhWxCtymmAS",
        "outputId": "f74edd2c-443a-412d-b0b8-59ed6338ac6d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SNN(\n",
              "  (cnn1): Sequential(\n",
              "    (0): Conv1d(1, 8, kernel_size=(3,), stride=(1,), padding=same)\n",
              "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
              "    (4): Conv1d(8, 12, kernel_size=(3,), stride=(1,), padding=same)\n",
              "    (5): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
              "  )\n",
              "  (fc1): Sequential(\n",
              "    (0): Linear(in_features=31344, out_features=1024, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=1024, out_features=128, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=128, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.66 s (started: 2023-11-28 11:04:29 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_KNN(test_image,k=6):\n",
        "  distances = []\n",
        "  for i in range(len(x_train)):\n",
        "    e1, e2 =loaded_model(torch.from_numpy(test_image).unsqueeze(1).to(device).float(),\n",
        "                                  torch.from_numpy(x_train[i]).unsqueeze(1).to(device).float())\n",
        "    eucledian_distance = F.pairwise_distance(e1, e2)\n",
        "    distances.append(eucledian_distance[0].item())\n",
        "\n",
        "  #k-nearest neighbors\n",
        "  nearest_neighbors_indices = np.argsort(distances)[:k]\n",
        "  print(y_train[nearest_neighbors_indices])\n",
        "\n",
        "  #majority voting\n",
        "  predicted_label = np.argmax(np.bincount(y_train[nearest_neighbors_indices]))\n",
        "  return predicted_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlJw2U6ZuBkf",
        "outputId": "2839b428-d5ec-4d7c-bc33-c11d0811f3ab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 943 Âµs (started: 2023-11-28 11:08:19 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = []\n",
        "for i in range(10):\n",
        "  predict.append(predict_KNN(x_val[i]))\n",
        "  # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdtqKJh6Niv9",
        "outputId": "81912899-7417-4014-f689-b8cedc20a992"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 2 0 1]\n",
            "[0 1 0 0 0 1]\n",
            "[0 1 2 2 0 0]\n",
            "[1 2 1 1 1 1]\n",
            "[2 2 0 2 0 0]\n",
            "[0 0 0 0 1 1]\n",
            "[1 0 0 0 2 2]\n",
            "[1 1 1 1 1 1]\n",
            "[0 0 0 0 1 0]\n",
            "[2 2 2 2 2 0]\n",
            "time: 1min 40s (started: 2023-11-28 11:08:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPhkHyZXKezI",
        "outputId": "94d8c214-99b7-4421-da9e-fa6dc9b49cc1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 1, 0, 0, 0, 1, 0, 2]\n",
            "time: 5.36 ms (started: 2023-11-28 11:10:03 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_val[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsFAXiIovlWF",
        "outputId": "2357e3d1-285c-495a-ca62-4c92f7cfbd8c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 0 1 0 2 0 2 1 1]\n",
            "time: 1.35 ms (started: 2023-11-28 11:10:03 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "  pass"
      ],
      "metadata": {
        "id": "lXW1Wcv4oVyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lnFABOVloX7a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}